{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepOnKHATT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OXV2NEE2gEN"
      },
      "source": [
        "---\r\n",
        "**NOTE** \\\r\n",
        "After installing tensorflow 1.5, you need to restart runtime. You will be asked to do so by clicking button upon installation completion.\r\n",
        "This notebook is developed to run on Colab.\r\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAoNBd2OoGBV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af5f3d07-c109-4d8b-dcea-b89e0942f144"
      },
      "source": [
        "!pip3 install tensorflow==1.15.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/2b/e3af15221da9ff323521565fa3324b0d7c7c5b1d7a8ca66984c8d59cb0ce/tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 41kB/s \n",
            "\u001b[?25hCollecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 9.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.10.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (3.12.4)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.12.1)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.36.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (3.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.15.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 52.2MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 52.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.1.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.32.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.2.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.8.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.19.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==1.15.0) (54.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.3.4)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.7.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.7.4.3)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7540 sha256=7ed6fbbba5e570ea31c55ed396bf98e01949117f8d69105b83be583354c00b41\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: keras-applications, gast, tensorboard, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: tensorflow 2.4.1\n",
            "    Uninstalling tensorflow-2.4.1:\n",
            "      Successfully uninstalled tensorflow-2.4.1\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pu-umFpU3zUX",
        "outputId": "b5b351e4-0445-42c8-888b-1a91a03b0260"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ay5so5B6IO4r",
        "outputId": "1f29b94f-5617-4c11-f6f9-9af496f4f7fc"
      },
      "source": [
        "!git clone https://github.com/fakhralwajih/DeepOnKHATT.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'DeepOnKHATT'...\n",
            "remote: Enumerating objects: 73, done.\u001b[K\n",
            "remote: Counting objects: 100% (73/73), done.\u001b[K\n",
            "remote: Compressing objects: 100% (58/58), done.\u001b[K\n",
            "remote: Total 73 (delta 11), reused 71 (delta 9), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (73/73), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuED-IaVIgkz"
      },
      "source": [
        "# change dir to DeepOnKHATT dir\r\n",
        "import os\r\n",
        "os.chdir('DeepOnKHATT')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7P-j-4WaPLU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c94769b2-0c55-4d83-87c4-f6f5ce02be1c"
      },
      "source": [
        "#download pre-trained models\r\n",
        "!gdown --id 1-YAltfi_4Klvu_-f72iSkHboM46-iH_t --output lm/trie\r\n",
        "!gdown --id 1MqhnAcXMwT_nq_z-01CRhWKLYJYZBa1A --output lm/lm.binary\r\n",
        "!gdown --id  1Z_gzzWVjskv_1JqErGuz8ZVfCSNaC3VY --output models/models.zip\r\n",
        "!unzip models/models.zip -d models/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-YAltfi_4Klvu_-f72iSkHboM46-iH_t\n",
            "To: /content/DeepOnKHATT/lm/trie\n",
            "14.0MB [00:00, 86.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1MqhnAcXMwT_nq_z-01CRhWKLYJYZBa1A\n",
            "To: /content/DeepOnKHATT/lm/lm.binary\n",
            "1.07GB [00:10, 100MB/s] \n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Z_gzzWVjskv_1JqErGuz8ZVfCSNaC3VY\n",
            "To: /content/DeepOnKHATT/models/models.zip\n",
            "344MB [00:04, 69.1MB/s]\n",
            "Archive:  models/models.zip\n",
            "  inflating: models/model.ckpt-14.meta  \n",
            "  inflating: models/model.ckpt-14.data-00000-of-00001  \n",
            "  inflating: models/model.ckpt-14.index  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_8U5bRxmDG9",
        "outputId": "970931d7-1a24-4ef1-a211-f3c00b453a3d"
      },
      "source": [
        "#install decoder \r\n",
        "!pip3 install ds_ctcdecoder==0.6.1"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ds_ctcdecoder==0.6.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/7b/7aee6c3e8a99671275d2123d699e12615db92f617cdcebed1d8cf6c4cbb2/ds_ctcdecoder-0.6.1-cp37-cp37m-manylinux1_x86_64.whl (5.6MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6MB 18.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from ds_ctcdecoder==0.6.1) (1.19.5)\n",
            "Installing collected packages: ds-ctcdecoder\n",
            "Successfully installed ds-ctcdecoder-0.6.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVby5o4sJOh4"
      },
      "source": [
        "from features.feature import calculate_feature_vector_sequence \r\n",
        "from features.preprocessing import preprocess_handwriting\r\n",
        "from rnn import BiRNN as BiRNN_model\r\n",
        "from datasets import pad_sequences,sparse_tuple_from ,handwriting_to_input_vector\r\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBu43UrasYS6"
      },
      "source": [
        "import argparse\r\n",
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "from ds_ctcdecoder import ctc_beam_search_decoder, Scorer\r\n",
        "from text import Alphabet,get_arabic_letters,decodex"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R40OahqYTsXr"
      },
      "source": [
        "letters_ar=get_arabic_letters()\r\n",
        "alphabet = Alphabet('alphabet.txt')\r\n",
        "#convert this to funcation\r\n",
        "mapping={}\r\n",
        "with open('arabic_mapping.txt','r', encoding='utf-8') as inf:\r\n",
        "    for line in inf:\r\n",
        "        key,val=line.split('\\t')\r\n",
        "        mapping[key]=val.strip()\r\n",
        "mapping[' ']=' '\r\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oWXqRfOS2WW"
      },
      "source": [
        "## imports for writing canvas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5G3uFlPoRCoU"
      },
      "source": [
        "from IPython.display import HTML, Image\r\n",
        "from google.colab.output import eval_js\r\n",
        "from base64 import b64decode"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnNUt7IFpAN-"
      },
      "source": [
        "from configparser import ConfigParser\r\n",
        "config_file='neural_network.ini'\r\n",
        "model_path='models/model.ckpt-14'\r\n",
        "parser = ConfigParser()\r\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RN73hDLVXQif"
      },
      "source": [
        "parser.read('neural_network.ini')\r\n",
        "config_header='nn'       \r\n",
        "network_type = parser.get(config_header , 'network_type')\r\n",
        "n_context = parser.getint(config_header, 'n_context') \r\n",
        "n_input = parser.getint(config_header, 'n_input')\r\n",
        "beam_search_decoder = parser.get(config_header, 'beam_search_decoder')        \r\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eU5OSIJpXUh"
      },
      "source": [
        "#LM setting\r\n",
        "config_header='lm' \r\n",
        "lm_alpha=parser.getfloat(config_header , 'lm_alpha')\r\n",
        "lm_beta=parser.getfloat(config_header , 'lm_beta')\r\n",
        "beam_width=parser.getint(config_header , 'beam_width')\r\n",
        "cutoff_prob=parser.getfloat(config_header , 'cutoff_prob')\r\n",
        "cutoff_top_n= parser.getint(config_header , 'cutoff_top_n')\r\n",
        "\r\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2vuzRk5Xt8r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "beef4734-6833-42d8-e624-e44b1bdae8ec"
      },
      "source": [
        "conf_path='neural_network.ini'\r\n",
        "input_tensor = tf.placeholder(tf.float32, [None, None, n_input + (2 * n_input * n_context)], name='input')    \r\n",
        "seq_length = tf.placeholder(tf.int32, [None], name='seq_length')\r\n",
        "logits, summary_op = BiRNN_model(conf_path,input_tensor,tf.to_int64(seq_length),n_input,n_context)\r\n",
        "#if you need to try greedy decoder without LM\r\n",
        "# decoded, log_prob = ctc_ops.ctc_greedy_decoder(logits, seq_length, merge_repeated=True)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-14-449b83e3e51b>:4: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/DeepOnKHATT/rnn.py:18: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/DeepOnKHATT/rnn.py:226: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /content/DeepOnKHATT/rnn.py:228: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
            "\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /content/DeepOnKHATT/rnn.py:259: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From /content/DeepOnKHATT/rnn.py:283: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:735: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:739: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/rnn.py:244: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/DeepOnKHATT/rnn.py:319: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tC1_jNJcZICI"
      },
      "source": [
        "lm_binary_path='lm/lm.binary'\r\n",
        "lm_trie_path='lm/trie'\r\n",
        "\r\n",
        "scorer=None\r\n",
        "scorer = Scorer(lm_alpha, lm_beta,lm_binary_path, lm_trie_path,alphabet)\r\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLoNGG3CbO2t"
      },
      "source": [
        "config_file='neural_network.ini'"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xq9TqgeIpYZh",
        "outputId": "9fad1683-372e-48c0-db6b-813322733d85"
      },
      "source": [
        "saver = tf.train.Saver()\r\n",
        "# create the session\r\n",
        "sess = tf.Session()\r\n",
        "saver.restore(sess, 'models/model.ckpt-14')\r\n",
        "print('Model restored') "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from models/model.ckpt-14\n",
            "Model restored\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zFfWNE4Y0F4"
      },
      "source": [
        "canvas_html = \"\"\"\r\n",
        "<canvas id=\"mycanvas\" width=%d height=%d style=\"border:1px solid #000000;\"></canvas>\r\n",
        " <br />\r\n",
        "<button>Recoginize</button>\r\n",
        "\r\n",
        "<script>\r\n",
        "var canvas = document.getElementById('mycanvas')\r\n",
        "var ctx = canvas.getContext('2d')\r\n",
        "ctx.lineWidth = %d\r\n",
        "ctx.canvas.style.touchAction = \"none\";\r\n",
        "var button = document.querySelector('button')\r\n",
        "var mouse = {x: 0, y: 0}\r\n",
        "var points=[]\r\n",
        "\r\n",
        "canvas.addEventListener('pointermove', function(e) {\r\n",
        "  mouse.x = e.pageX - this.offsetLeft\r\n",
        "  mouse.y = e.pageY - this.offsetTop\r\n",
        "})\r\n",
        "canvas.onpointerdown = ()=>{\r\n",
        "  ctx.beginPath()\r\n",
        "  ctx.moveTo(mouse.x, mouse.y)\r\n",
        "  \r\n",
        "  canvas.addEventListener('pointermove', onPaint)\r\n",
        "}\r\n",
        "canvas.onpointerup = ()=>{\r\n",
        "  canvas.removeEventListener('pointermove', onPaint)\r\n",
        "  points.pop()\r\n",
        "  points.push([mouse.x,mouse.y,1])\r\n",
        "}\r\n",
        "var onPaint = ()=>{\r\n",
        "  ctx.lineTo(mouse.x, mouse.y)\r\n",
        "  ctx.stroke()\r\n",
        "  points.push([mouse.x,mouse.y,0])\r\n",
        "}\r\n",
        "var data = new Promise(resolve=>{\r\n",
        "  button.onclick = ()=>{\r\n",
        "    resolve(canvas.toDataURL('image/png'))\r\n",
        "  }\r\n",
        "})\r\n",
        "</script>\r\n",
        "\"\"\"\r\n",
        "def draw(filename='drawing.png', w=900, h=200, line_width=1):\r\n",
        "  display(HTML(canvas_html % (w, h, line_width)))\r\n",
        "  data = eval_js(\"data\")\r\n",
        "  points=eval_js(\"points\")\r\n",
        "  # strokes = Utils.Rearrange(strokes, 20);\r\n",
        "  points=np.array(points)\r\n",
        "\r\n",
        "  # points=rearrange(points)\r\n",
        "\r\n",
        "\r\n",
        "  # print(\"Points before pre\",points.shape)\r\n",
        "  NORM_ARGS = [\"origin\",\"filp_h\",\"smooth\", \"slope\", \"resample\", \"slant\", \"height\"]\r\n",
        "  FEAT_ARGS = [\"x_cor\",\"y_cor\",\"penup\",\"dir\", \"curv\", \"vic_aspect\", \"vic_curl\", \"vic_line\", \"vic_slope\", \"bitmap\"]\r\n",
        "  # print(\"Normalizing trajectory...\")\r\n",
        "  traj = preprocess_handwriting(points, NORM_ARGS)\r\n",
        "  # print(traj)\r\n",
        "  # print(\"Calculating feature vector sequence...\")\r\n",
        "  feat_seq_mat = calculate_feature_vector_sequence(traj, FEAT_ARGS)\r\n",
        "  feat_seq_mat=feat_seq_mat.astype('float32')\r\n",
        "  feat_seq_mat.shape\r\n",
        "\r\n",
        "  data = []\r\n",
        "\r\n",
        "  train_input=handwriting_to_input_vector(feat_seq_mat,20,9)\r\n",
        "  train_input = train_input.astype('float32')\r\n",
        "\r\n",
        "  data.append(train_input)\r\n",
        "  # data_len\r\n",
        "\r\n",
        "  data = np.asarray(data)\r\n",
        "  # data_len = np.asarray(train_input)\r\n",
        "\r\n",
        "\r\n",
        "  # Pad input to max_time_step of this batch\r\n",
        "  source, source_lengths = pad_sequences(data)\r\n",
        "  my_logits=sess.run(logits, feed_dict={\r\n",
        "                  input_tensor: source,                    \r\n",
        "                  seq_length: source_lengths}\r\n",
        "              )\r\n",
        "  my_logits = np.squeeze(my_logits)\r\n",
        "  maxT, _ = my_logits.shape # dim0=t, dim1=c\r\n",
        "\t\r\n",
        "            # apply softmax\r\n",
        "  res = np.zeros(my_logits.shape)\r\n",
        "  for t in range(maxT):\r\n",
        "      y = my_logits[t, :]\r\n",
        "      e = np.exp(y)\r\n",
        "      s = np.sum(e)\r\n",
        "      res[t, :] = e / s\r\n",
        "            \r\n",
        "  decoded = ctc_beam_search_decoder(res, alphabet, beam_width,\r\n",
        "                                  scorer=scorer, cutoff_prob=cutoff_prob,\r\n",
        "                                  cutoff_top_n=cutoff_top_n)\r\n",
        "\r\n",
        "  print(\"Result : \"+decodex(decoded[0][1],mapping))\r\n",
        "  "
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Cj527QnPodk"
      },
      "source": [
        "**Note**  \\\r\n",
        "The next cell, you can run multiple times as you wish. You may want to write many samples. \\\r\n",
        "All the above cells should run only once. \\\r\n",
        "\r\n",
        "Run the cell and write on the canvas while the cell is running. Then, click on \"Recoginize\" button to get the recognition result.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1Uvk3xxp3Bj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "171bec70-4766-4608-e5d7-b7ace3560c53"
      },
      "source": [
        "draw()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "<canvas id=\"mycanvas\" width=900 height=200 style=\"border:1px solid #000000;\"></canvas>\n",
              " <br />\n",
              "<button>Recoginize</button>\n",
              "\n",
              "<script>\n",
              "var canvas = document.getElementById('mycanvas')\n",
              "var ctx = canvas.getContext('2d')\n",
              "ctx.lineWidth = 1\n",
              "ctx.canvas.style.touchAction = \"none\";\n",
              "var button = document.querySelector('button')\n",
              "var mouse = {x: 0, y: 0}\n",
              "var points=[]\n",
              "\n",
              "canvas.addEventListener('pointermove', function(e) {\n",
              "  mouse.x = e.pageX - this.offsetLeft\n",
              "  mouse.y = e.pageY - this.offsetTop\n",
              "})\n",
              "canvas.onpointerdown = ()=>{\n",
              "  ctx.beginPath()\n",
              "  ctx.moveTo(mouse.x, mouse.y)\n",
              "  \n",
              "  canvas.addEventListener('pointermove', onPaint)\n",
              "}\n",
              "canvas.onpointerup = ()=>{\n",
              "  canvas.removeEventListener('pointermove', onPaint)\n",
              "  points.pop()\n",
              "  points.push([mouse.x,mouse.y,1])\n",
              "}\n",
              "var onPaint = ()=>{\n",
              "  ctx.lineTo(mouse.x, mouse.y)\n",
              "  ctx.stroke()\n",
              "  points.push([mouse.x,mouse.y,0])\n",
              "}\n",
              "var data = new Promise(resolve=>{\n",
              "  button.onclick = ()=>{\n",
              "    resolve(canvas.toDataURL('image/png'))\n",
              "  }\n",
              "})\n",
              "</script>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result : الله\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KT69P5KQ09D"
      },
      "source": [
        "The above canvas was tested on PC mouse and S pen (samsung tablet) and works well with S pen."
      ]
    }
  ]
}